{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Quant Apprentice: Final Submission\n",
    "\n",
    "**Version 2.0: Agentic Graph Workflow**\n",
    "\n",
    "This notebook represents the final, self-contained version of the Quant Apprentice project. It implements a sophisticated, multi-step financial analysis agent using a stateful graph architecture.\n",
    "\n",
    "### Core Agentic Capabilities Demonstrated:\n",
    "- **Planning & Execution**: The agent follows a multi-node graph that defines a clear, repeatable research plan (see Section 4).\n",
    "- **Dynamic Tool Use**: It leverages external APIs for real-time financial, news, and SEC filing data (see Section 3.1).\n",
    "- **Self-Reflection**: It uses an explicit Evaluator-Optimizer loop within the graph to critique and refine its own analysis (see Section 4, `evaluate_report_node` and `should_refine_or_end`).\n",
    "- **Learning (Memory)**: It incorporates a vector database (ChromaDB) to perform semantic searches on past analyses, demonstrating a Retrieval-Augmented Generation (RAG) pattern (see Section 3.2 and graph nodes `retrieve_from_memory_node`, `save_to_memory_node`).\n",
    "\n",
    "### Agentic Workflow Patterns Implemented:\n",
    "1.  **Prompt Chaining**: The `analyze_article_chain` function processes raw news into structured JSON (see Section 3.3).\n",
    "2.  **Task Routing**: The `route_and_execute_task` function directs data to specialized analyst prompts (see Section 4).\n",
    "3.  **Evaluator-Optimizer Loop**: The graph's conditional edge (`should_refine_or_end`) and refinement loop embody this pattern (see Section 4).\n",
    "\n",
    "This notebook contains all necessary code to run the agent. Simply install the dependencies, add your API keys, and execute the cells in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell installs all necessary libraries.\n",
    "%pip install --upgrade --quiet google-generativeai langgraph yfinance fredapi newsapi-python sec-api python-dotenv pandas chromadb sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries for the agent\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import TypedDict, List\n",
    "\n",
    "# External Data and AI Libraries\n",
    "import yfinance as yf\n",
    "from fredapi import Fred\n",
    "from newsapi import NewsApiClient\n",
    "from sec_api import QueryApi\n",
    "import google.generativeai as genai\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Agentic Graph Library\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Notebook Display Utilities\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "print(\"âœ… All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. API Key Configuration\n",
    "\n",
    "**Action Required**: You must add your API keys to run this notebook. The easiest way is to create a `.env` file in the same directory as this notebook and paste the following content into it, replacing `\"YOUR_KEY_HERE\"` with your actual keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "llm = genai.GenerativeModel('gemini-2.5-pro', generation_config={'temperature': 0.2})\n",
    "fred = Fred(api_key=os.getenv(\"FRED_API_KEY\"))\n",
    "newsapi = NewsApiClient(api_key=os.getenv(\"NEWS_API_KEY\"))\n",
    "query_api = QueryApi(api_key=os.getenv(\"SEC_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Self-Contained Agent Components\n",
    "\n",
    "This section consolidates all the Python code from the project's external modules (`tools`, `workflows`, `memory`) into this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Tool Belt Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_fundamentals(ticker_symbol: str) -> dict:\n",
    "    \"\"\"Fetches key fundamental data for a given stock ticker using yfinance.\"\"\"\n",
    "    print(f\"--- [Tool Action]: Fetching fundamental data for {ticker_symbol}... ---\")\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker_symbol)\n",
    "        info = stock.info\n",
    "        fundamentals = {\n",
    "            \"ticker\": ticker_symbol,\n",
    "            \"companyName\": info.get(\"longName\"),\n",
    "            \"sector\": info.get(\"sector\"),\n",
    "            \"industry\": info.get(\"industry\"),\n",
    "            \"marketCap\": info.get(\"marketCap\"),\n",
    "            \"enterpriseValue\": info.get(\"enterpriseValue\"),\n",
    "            \"trailingPE\": info.get(\"trailingPE\"),\n",
    "            \"forwardPE\": info.get(\"forwardPE\"),\n",
    "            \"trailingEps\": info.get(\"trailingEps\"),\n",
    "            \"priceToBook\": info.get(\"priceToBook\"),\n",
    "            \"dividendYield\": info.get(\"dividendYield\"),\n",
    "            \"payoutRatio\": info.get(\"payoutRatio\"),\n",
    "        }\n",
    "        print(f\"--- [Tool Success]: Successfully fetched fundamentals for {ticker_symbol}. ---\")\n",
    "        return fundamentals\n",
    "    except Exception as e:\n",
    "        error_message = f\"Could not fetch data for {ticker_symbol}. Ticker might be invalid. Details: {e}\"\n",
    "        print(f\"--- [Tool Error]: {error_message} ---\")\n",
    "        return {\"error\": error_message}\n",
    "\n",
    "def get_macro_economic_data(api_key: str) -> dict:\n",
    "    \"\"\"Fetches key US macroeconomic indicators from the FRED API.\"\"\"\n",
    "    print(\"--- [Tool Action]: Fetching macroeconomic data from FRED... ---\")\n",
    "    try:\n",
    "        fred = Fred(api_key=api_key)\n",
    "        series_ids = {\n",
    "            \"GDP_Growth\": \"GDP\",\n",
    "            \"UnemploymentRate\": \"UNRATE\",\n",
    "            \"InflationRate_CPI\": \"CPIAUCSL\",\n",
    "            \"EffectiveFedFundsRate\": \"FEDFUNDS\",\n",
    "        }\n",
    "        macro_data = {}\n",
    "        for name, series_id in series_ids.items():\n",
    "            data = fred.get_series_latest_release(series_id)\n",
    "            macro_data[name] = data.iloc[-1]\n",
    "        print(\"--- [Tool Success]: Successfully fetched macroeconomic data. ---\")\n",
    "        return macro_data\n",
    "    except Exception as e:\n",
    "        error_message = f\"Could not fetch FRED data. Check API key or connection. Details: {e}\"\n",
    "        print(f\"--- [Tool Error]: {error_message} ---\")\n",
    "        return {\"error\": error_message}\n",
    "\n",
    "def get_company_news(company_name: str, api_key: str, num_articles: int = 3) -> dict:\n",
    "    \"\"\"Fetches and processes top news headlines for a given company using the NewsAPI.\"\"\"\n",
    "    print(f\"--- [Tool Action]: Fetching top {num_articles} news articles for {company_name}... ---\")\n",
    "    try:\n",
    "        newsapi = NewsApiClient(api_key=api_key)\n",
    "        top_headlines = newsapi.get_everything(\n",
    "            q=company_name,\n",
    "            language='en',\n",
    "            sort_by='relevancy',\n",
    "            page_size=num_articles\n",
    "        )\n",
    "        if top_headlines['status'] != 'ok':\n",
    "            return {\"error\": \"Failed to fetch news from NewsAPI.\"}\n",
    "        processed_articles = []\n",
    "        for article in top_headlines['articles']:\n",
    "            processed_articles.append({\n",
    "                \"source\": article['source']['name'],\n",
    "                \"title\": article['title'],\n",
    "                \"url\": article['url'],\n",
    "                \"publishedAt\": article['publishedAt'],\n",
    "                \"content\": article.get('content', 'No content available.')\n",
    "            })\n",
    "        print(f\"--- [Tool Success]: Successfully fetched {len(processed_articles)} articles. ---\")\n",
    "        return {\"articles\": processed_articles}\n",
    "    except Exception as e:\n",
    "        error_message = f\"An error occurred while fetching news: {e}\"\n",
    "        print(f\"--- [Tool Error]: {error_message} ---\")\n",
    "        return {\"error\": error_message}\n",
    "\n",
    "def get_latest_sec_filings(company_ticker: str, api_key: str) -> dict:\n",
    "    \"\"\"Fetches the most recent 10-K and 10-Q filings for a company.\"\"\"\n",
    "    print(f\"--- [Tool Action]: Fetching latest SEC filings for {company_ticker}... ---\")\n",
    "    try:\n",
    "        queryApi = QueryApi(api_key=api_key)\n",
    "        query = {\n",
    "          \"query\": { \"query_string\": {\n",
    "              \"query\": f\"ticker:{company_ticker} AND formType:\\\"10-K\\\" OR formType:\\\"10-Q\\\"\"\n",
    "          }},\n",
    "          \"from\": \"0\",\n",
    "          \"size\": \"1\",\n",
    "          \"sort\": [{ \"filedAt\": { \"order\": \"desc\" } }]\n",
    "        }\n",
    "        response = queryApi.get_filings(query)\n",
    "        if not response['filings']:\n",
    "            return {\"error\": f\"No recent 10-K or 10-Q found for {company_ticker}.\"}\n",
    "        latest_filing = response['filings'][0]\n",
    "        filing_url = latest_filing['linkToFilingDetails']\n",
    "        print(f\"--- [Tool Success]: Found latest filing: {latest_filing['formType']} filed on {latest_filing['filedAt'][:10]} ---\")\n",
    "        # In a real-world scenario, you would use an extraction API to get the text.\n",
    "        # For this project, we simulate the output to demonstrate the capability.\n",
    "        return {\n",
    "            \"filing_type\": latest_filing['formType'],\n",
    "            \"filed_at\": latest_filing['filedAt'],\n",
    "            \"link_to_filing\": filing_url,\n",
    "            \"summary_of_risk_factors\": f\"Extracted key risk factors related to competition and market trends for {company_ticker}.\",\n",
    "            \"summary_of_mdna\": f\"Extracted management's discussion on financial performance and future outlook for {company_ticker}.\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"--- [Tool Error]: Failed to fetch SEC filings. Details: {e} ---\")\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Vector Memory System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorMemory:\n",
    "    \"\"\"A class to manage agent memory using a ChromaDB vector database.\"\"\"\n",
    "    def __init__(self, db_path: str = \"chroma_db_memory\"):\n",
    "        print(f\"--- [Memory]: Initializing ChromaDB at {db_path} ---\")\n",
    "        self.client = chromadb.PersistentClient(path=db_path)\n",
    "        self.collection = self.client.get_or_create_collection(name=\"quant_apprentice_memory\")\n",
    "\n",
    "    def add_analysis(self, ticker: str, report_text: str):\n",
    "        print(f\"--- [Memory]: Adding analysis for {ticker} to vector memory... ---\")\n",
    "        try:\n",
    "            current_date = datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "            unique_id = f\"{ticker}_{current_date}\"\n",
    "            self.collection.add(\n",
    "                documents=[report_text],\n",
    "                metadatas=[{\"ticker\": ticker, \"date\": current_date}],\n",
    "                ids=[unique_id]\n",
    "            )\n",
    "            print(f\"--- [Memory]: Successfully added document with ID: {unique_id} ---\")\n",
    "        except Exception as e:\n",
    "            print(f\"--- [Memory Error]: Failed to add analysis for {ticker}. Details: {e} ---\")\n",
    "\n",
    "    def query_memory(self, query_text: str, n_results: int = 1) -> list:\n",
    "        print(f\"--- [Memory]: Querying memory with: '{query_text}' ---\")\n",
    "        try:\n",
    "            results = self.collection.query(query_texts=[query_text], n_results=n_results)\n",
    "            return results.get('documents', [[]])[0]\n",
    "        except Exception as e:\n",
    "            print(f\"--- [Memory Error]: Failed to query memory. Details: {e} ---\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Workflow Function (Prompt Chaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_article_chain(article_content: str, llm_model: genai.GenerativeModel) -> dict:\n",
    "    \"\"\"(WORKFLOW 1: PROMPT CHAINING) Analyzes a news article using a structured prompt for financial sentiment.\"\"\"\n",
    "    print(\"--- [Workflow Action]: Starting Refined News Analysis Chain... ---\")\n",
    "    prompt = f\"\"\"\n",
    "    You are a skeptical financial analyst. Analyze the following news article from a cautious investor's perspective.\n",
    "    **Analysis Steps:**\n",
    "    1. **Reasoning:** In one sentence, explain the financial impact on the company's bottom line or market position.\n",
    "    2. **Sentiment Classification:** Based only on your reasoning, classify the sentiment as 'Positive', 'Negative', or 'Neutral' according to the rubric.\n",
    "    3. **Key Takeaways:** Extract the 3 most important bullet-point takeaways.\n",
    "    4. **Summary:** Provide a concise 2-sentence summary.\n",
    "    **Sentiment Rubric:**\n",
    "    - **Positive**: Favorable impact on revenue, earnings, or market share.\n",
    "    - **Negative**: Direct risk to earnings, operations, or reputation.\n",
    "    - **Neutral**: Informational but no clear, immediate financial impact.\n",
    "    **Article Content:**\n",
    "    ---\n",
    "    {article_content}\n",
    "    ---\n",
    "    Provide the output in a single, valid JSON object with keys: \"reasoning\", \"sentiment\", \"key_takeaways\", \"summary\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not article_content or len(article_content.strip()) < 20:\n",
    "            return {\"error\": \"Content too short for analysis.\"}\n",
    "        response = llm_model.generate_content(prompt)\n",
    "        cleaned_response = re.sub(r\"```json\\n?|```\", \"\", response.text)\n",
    "        analysis_result = json.loads(cleaned_response)\n",
    "        print(\"--- [Workflow Success]: Refined News Analysis completed. ---\")\n",
    "        return analysis_result\n",
    "    except Exception as e:\n",
    "        error_message = f\"Failed to analyze article. Details: {e}\"\n",
    "        print(f\"--- [Workflow Error]: {error_message} ---\")\n",
    "        return {\"error\": error_message}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agent Graph Definition\n",
    "\n",
    "This is the core of the Version 2 agent. It defines the state, nodes, and edges of the agentic workflow using LangGraph. All prompts and workflow logic are consolidated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PROMPT TEMPLATES --- \n",
    "FINANCIAL_ANALYST_PROMPT = \"\"\"\n",
    "As a Quantitative Financial Analyst, analyze the provided key financial metrics. Focus on valuation, profitability, and financial health. Provide a 3-5 bullet point summary highlighting strengths and weaknesses. Be objective and data-driven.\n",
    "**Financial Data:**\n",
    "{financial_data}\n",
    "\"\"\"\n",
    "\n",
    "NEWS_ANALYST_PROMPT = \"\"\"\n",
    "As an Investment News Analyst, interpret the provided structured news analyses. What is the likely short-term impact on the company's stock price? Provide a 2-3 sentence summary of your impact assessment.\n",
    "**Structured News Analysis:**\n",
    "{news_analysis}\n",
    "\"\"\"\n",
    "\n",
    "MARKET_ANALYST_PROMPT = \"\"\"\n",
    "As a Macroeconomic Analyst, provide market context. How might the current economic environment (inflation, interest rates, GDP) affect the broader stock market and the company's sector? Provide a 2-3 sentence summary.\n",
    "**Macroeconomic Data:**\n",
    "{macro_data}\n",
    "\"\"\"\n",
    "\n",
    "SYNTHESIS_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a Chief Investment Strategist. Synthesize the reports from your specialist teams, your memory, and SEC filings into a final investment report for {company_name}.\n",
    "The report must include: Executive Summary, Key Findings, Final Recommendation (Buy/Hold/Sell), and Justification.\n",
    "\n",
    "**PRIOR ANALYSIS (from memory):**\n",
    "{past_analysis}\n",
    "---\n",
    "**LATEST SEC FILING INSIGHTS:**\n",
    "{sec_filings_summary}\n",
    "---\n",
    "**CURRENT SPECIALIST REPORTS:**\n",
    "1. Quantitative Financial Analysis:\n",
    "{financial_analysis}\n",
    "2. News Impact Analysis:\n",
    "{news_impact_analysis}\n",
    "3. Macroeconomic Context:\n",
    "{market_context_analysis}\n",
    "\"\"\"\n",
    "\n",
    "EVALUATOR_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a skeptical Risk Manager. Critique the following draft report. Identify potential weaknesses, biases, or gaps. Focus on whether the recommendation is well-supported. Provide feedback in a concise, 2-4 bullet point list.\n",
    "**DRAFT REPORT TO EVALUATE:**\n",
    "{draft_report}\n",
    "\"\"\"\n",
    "\n",
    "REFINEMENT_PROMPT_TEMPLATE = \"\"\"\n",
    "You are the Chief Investment Strategist. Revise your report based on the Risk Manager's feedback to create a more robust final version.\n",
    "**Original Specialist Reports & Data:**\n",
    "Financial Analysis: {financial_analysis}\n",
    "News Analysis: {news_impact_analysis}\n",
    "Macro Context: {market_context_analysis}\n",
    "\n",
    "**Risk Manager's Feedback:**\n",
    "{feedback}\n",
    "\n",
    "Now, generate the final, refined investment report for {company_name}.\n",
    "\"\"\"\n",
    "\n",
    "# --- AGENT STATE --- \n",
    "class AgentState(TypedDict):\n",
    "    company_name: str\n",
    "    company_ticker: str\n",
    "    financial_data: dict\n",
    "    macro_data: dict\n",
    "    news_data: dict\n",
    "    sec_filings_data: dict\n",
    "    past_analysis: str\n",
    "    structured_news_analysis: dict\n",
    "    financial_analysis: str\n",
    "    news_impact_analysis: str\n",
    "    market_context_analysis: str\n",
    "    draft_report: str\n",
    "    feedback: str\n",
    "    final_report: str\n",
    "    revision_count: int\n",
    "\n",
    "# --- WORKFLOW & NODE FUNCTIONS ---\n",
    "\n",
    "def route_and_execute_task(task_type: str, data: dict, llm_model: genai.GenerativeModel) -> str:\n",
    "    \"\"\"(WORKFLOW 2: TASK ROUTING) Routes data to the correct specialist analyst prompt.\"\"\"\n",
    "    prompt_map = {\n",
    "        'analyze_financials': FINANCIAL_ANALYST_PROMPT.format(financial_data=data),\n",
    "        'analyze_news_impact': NEWS_ANALYST_PROMPT.format(news_analysis=data),\n",
    "        'analyze_market_context': MARKET_ANALYST_PROMPT.format(macro_data=data)\n",
    "    }\n",
    "    prompt = prompt_map.get(task_type)\n",
    "    if not prompt:\n",
    "        return f\"--- [Router Error]: Invalid task type: {task_type} ---\"\n",
    "    print(f\"--- [Router]: Routing to {task_type.split('_')[1].capitalize()} Analyst... ---\")\n",
    "    try:\n",
    "        response = llm_model.generate_content(prompt)\n",
    "        print(f\"--- [Router]: Specialist analysis complete. ---\")\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"--- [Router Error]: {e} ---\"\n",
    "\n",
    "def gather_data_node(state: AgentState):\n",
    "    print(\"--- [Node]: Gathering Data... ---\")\n",
    "    company_name = state['company_name']\n",
    "    company_ticker = state['company_ticker']\n",
    "    financial_data = get_stock_fundamentals(company_ticker)\n",
    "    macro_data = get_macro_economic_data(os.getenv(\"FRED_API_KEY\"))\n",
    "    news_data = get_company_news(company_name, os.getenv(\"NEWS_API_KEY\"), num_articles=3)\n",
    "    return {\"financial_data\": financial_data, \"macro_data\": macro_data, \"news_data\": news_data}\n",
    "\n",
    "def retrieve_from_memory_node(state: AgentState):\n",
    "    print(\"--- [Node]: Retrieving from Vector Memory... ---\")\n",
    "    company_name = state['company_name']\n",
    "    memory = VectorMemory()\n",
    "    query = f\"What was my past analysis and conclusion for {company_name}?\"\n",
    "    results = memory.query_memory(query, n_results=1)\n",
    "    past_analysis = \"\\n\".join(results) if results else \"No prior analysis found in memory.\"\n",
    "    print(f\"--- [Memory]: Found relevant past analysis.\" if results else \"--- [Memory]: No relevant past analysis found. ---\")\n",
    "    return {\"past_analysis\": past_analysis}\n",
    "\n",
    "def sec_filings_node(state: AgentState):\n",
    "    print(\"--- [Node]: Fetching SEC Filings... ---\")\n",
    "    company_ticker = state['company_ticker']\n",
    "    sec_data = get_latest_sec_filings(company_ticker, os.getenv(\"SEC_API_KEY\"))\n",
    "    return {\"sec_filings_data\": sec_data}\n",
    "\n",
    "def specialist_analysis_node(state: AgentState):\n",
    "    print(\"--- [Node]: Performing Specialist Analysis... ---\")\n",
    "    processed_analyses = [analyze_article_chain(article['content'], llm) for article in state[\"news_data\"].get(\"articles\", [])]\n",
    "    structured_news_analysis = {\"news_items\": processed_analyses}\n",
    "    financial_analysis = route_and_execute_task('analyze_financials', state['financial_data'], llm)\n",
    "    news_impact_analysis = route_and_execute_task('analyze_news_impact', structured_news_analysis, llm)\n",
    "    market_context_analysis = route_and_execute_task('analyze_market_context', state['macro_data'], llm)\n",
    "    return {\"structured_news_analysis\": structured_news_analysis, \"financial_analysis\": financial_analysis, \"news_impact_analysis\": news_impact_analysis, \"market_context_analysis\": market_context_analysis}\n",
    "\n",
    "def synthesize_report_node(state: AgentState):\n",
    "    print(\"--- [Node]: Synthesizing Draft Report... ---\")\n",
    "    prompt = SYNTHESIS_PROMPT_TEMPLATE.format(\n",
    "        company_name=state['company_name'],\n",
    "        past_analysis=state['past_analysis'],\n",
    "        sec_filings_summary=state.get('sec_filings_data', 'Not available'),\n",
    "        financial_analysis=state['financial_analysis'],\n",
    "        news_impact_analysis=state['news_impact_analysis'],\n",
    "        market_context_analysis=state['market_context_analysis']\n",
    "    )\n",
    "    draft_report = llm.generate_content(prompt).text\n",
    "    revision_count = state.get('revision_count', 0) + 1\n",
    "    return {\"draft_report\": draft_report, \"revision_count\": revision_count}\n",
    "\n",
    "def evaluate_report_node(state: AgentState):\n",
    "    print(\"--- [Node]: Evaluating Draft Report... ---\")\n",
    "    prompt = EVALUATOR_PROMPT_TEMPLATE.format(draft_report=state['draft_report'])\n",
    "    feedback = llm.generate_content(prompt).text\n",
    "    return {\"feedback\": feedback}\n",
    "\n",
    "def refine_report_node(state: AgentState):\n",
    "    print(\"--- [Node]: Refining Final Report... ---\")\n",
    "    prompt = REFINEMENT_PROMPT_TEMPLATE.format(\n",
    "        company_name=state['company_name'],\n",
    "        financial_analysis=state['financial_analysis'],\n",
    "        news_impact_analysis=state['news_impact_analysis'],\n",
    "        market_context_analysis=state['market_context_analysis'],\n",
    "        feedback=state['feedback']\n",
    "    )\n",
    "    final_report = llm.generate_content(prompt).text\n",
    "    return {\"final_report\": final_report}\n",
    "\n",
    "def save_to_memory_node(state: AgentState):\n",
    "    print(\"--- [Node]: Saving to Vector Memory... ---\")\n",
    "    company_ticker = state['company_ticker']\n",
    "    report_to_save = state.get('final_report') or state.get('draft_report')\n",
    "    if report_to_save:\n",
    "        memory = VectorMemory()\n",
    "        memory.add_analysis(company_ticker, report_to_save)\n",
    "    return {}\n",
    "\n",
    "# --- CONDITIONAL EDGE --- \n",
    "def should_refine_or_end(state: AgentState):\n",
    "    \"\"\"(WORKFLOW 3: EVALUATOR-OPTIMIZER) Uses the LLM to decide whether to refine the report or end the process.\"\"\"\n",
    "    print(\"--- [Conditional Edge]: Using LLM to check feedback... ---\")\n",
    "    if state['revision_count'] > 1:\n",
    "        print(\"--- [Decision]: Maximum revisions reached. Ending. ---\")\n",
    "        return \"end\"\n",
    "    decision_prompt = f\"\"\"You are a gatekeeper. Decide if a report needs revision based on the following feedback. If the feedback points out flaws or weaknesses, a revision is required. Answer ONLY with 'Yes' or 'No'.\\nFeedback:\\n{state['feedback']}\"\"\"\n",
    "    try:\n",
    "        response = llm.generate_content(decision_prompt)\n",
    "        decision = response.text.strip().lower()\n",
    "        if \"yes\" in decision:\n",
    "            print(\"--- [LLM Decision]: Feedback requires revision. Refining report. ---\")\n",
    "            return \"refine\"\n",
    "        else:\n",
    "            print(\"--- [LLM Decision]: Feedback is positive. Ending. ---\")\n",
    "            return \"end\"\n",
    "    except Exception as e:\n",
    "        print(f\"--- [Error]: Could not make a decision. Defaulting to end. Details: {e} ---\")\n",
    "        return \"end\"\n",
    "\n",
    "# --- GRAPH ASSEMBLY --- \n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"gather_data\", gather_data_node)\n",
    "workflow.add_node(\"retrieve_from_memory\", retrieve_from_memory_node)\n",
    "workflow.add_node(\"fetch_sec_filings\", sec_filings_node)\n",
    "workflow.add_node(\"analyze_specialists\", specialist_analysis_node)\n",
    "workflow.add_node(\"synthesize_report\", synthesize_report_node)\n",
    "workflow.add_node(\"evaluate_report\", evaluate_report_node)\n",
    "workflow.add_node(\"refine_report\", refine_report_node)\n",
    "workflow.add_node(\"save_to_memory\", save_to_memory_node)\n",
    "\n",
    "workflow.set_entry_point(\"gather_data\")\n",
    "workflow.add_edge(\"gather_data\", \"retrieve_from_memory\")\n",
    "workflow.add_edge(\"retrieve_from_memory\", \"fetch_sec_filings\")\n",
    "workflow.add_edge(\"fetch_sec_filings\", \"analyze_specialists\")\n",
    "workflow.add_edge(\"analyze_specialists\", \"synthesize_report\")\n",
    "workflow.add_edge(\"synthesize_report\", \"evaluate_report\")\n",
    "workflow.add_edge(\"refine_report\", \"save_to_memory\")\n",
    "workflow.add_edge(\"save_to_memory\", END)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"evaluate_report\",\n",
    "    should_refine_or_end,\n",
    "    {\"refine\": \"refine_report\", \"end\": \"save_to_memory\"}\n",
    ")\n",
    "\n",
    "app = workflow.compile()\n",
    "print(\"âœ… Agent Graph compiled successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agent Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agent Configuration ---\n",
    "company_name = \"NVIDIA\"\n",
    "company_ticker = \"NVDA\"\n",
    "\n",
    "initial_state = {\n",
    "    \"company_name\": company_name,\n",
    "    \"company_ticker\": company_ticker,\n",
    "    \"revision_count\": 0\n",
    "}\n",
    "\n",
    "print(f\"ðŸš€ Starting Quant Apprentice agent for {company_name}...\")\n",
    "\n",
    "# --- Run the Agentic Graph ---\n",
    "final_state = app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"âœ… Agent run complete.\")\n",
    "print(\"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Display Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if final_state:\n",
    "    display(Markdown(f\"# Final Investment Report: {company_name} ({company_ticker})\"))\n",
    "    \n",
    "    # The final report will either be in 'final_report' (if refined) or 'draft_report' (if the first draft was approved).\n",
    "    report_to_display = final_state.get('final_report', final_state.get('draft_report', \"*No report was generated.*\"))\n",
    "    feedback = final_state.get('feedback', \"*No feedback was generated.*\")\n",
    "    \n",
    "    display(Markdown(\"---\"))\n",
    "    display(Markdown(\"## Final Critic's Feedback:\"))\n",
    "    display(Markdown(feedback))\n",
    "    \n",
    "    display(Markdown(\"---\"))\n",
    "    display(Markdown(\"## **Final Report Delivered:**\"))\n",
    "    display(Markdown(report_to_display))\n",
    "else:\n",
    "    display(Markdown(f\"# Agent Run Failed for {company_name}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
